\documentclass[letterpaper,10pt,onecolumn,draftclsnofoot]{IEEEtran}
\usepackage{times}

\usepackage[english]{babel}
\usepackage[margin=0.75in]{geometry}

\usepackage{graphicx}

\DeclareGraphicsExtensions{.pdf,.png,.jpg}

\title{Object Speed Tracking}
\author{Tech Review\\Alex Bailey, Ben Wick, Dylan Washburne\\CS 461, Fall Term}

\begin{document}

\begin{titlepage}

\maketitle

\begin{abstract}
While we could consider whether we would use a singular camera or multiple, there is really no debate here.
Stereoscopic cameras carry such an advantage for a project like this, we are making that decision.
 
\end{abstract}

\end{titlepage}

\tableofcontents
\newpage

\section{Introduction}
This document is a detailed review of multiple technology options considered for our project. Each piece of technology has three options that is being compared. It includes reviews of live data feed, synchronization, and long-term compression written by Alex Bailey. Also reviewed, are options for long-term storage, computer vision libraries, and object tracking algorithms written by Ben Wick. Finally, written by Dylan Washburne, includes live compression, UI overlay, and video to velocity formulas.

\section{Technologies}

\subsection{Live Data Feed} %Alex

Both images simultaneously
Both images plus depth information
Singular image with depth

\newpage
\subsection{Synchronization} %Alex

two cameras, each sends images and computer works to compensate for any desyncronization
two cameras with global shutter, send back 2 images
2 cameras which do image splicing and send back spliced image to computer


\newpage
\subsection{Long-Term Compression} %Alex 
%Lossless
%Lossy
%No Compression

The options that we will be looking at are Xvid, FFV1, OpenH264.
The goals for this piece of the project is to compress the video after it has been displayed to the user, to be kept for long term, should they be needed at a later date.
With our product, it is likely that the user will be leaving our product running for a significant amount of time, possibly hours.
When this happens, video files can become rather large.
This will become a problem for long term storage if our product is used often.
So, the answer to this problem is to use a compression encoder/decoder, codec.
This will reduce the size of the video as much as possible.
There are several factors to consider when looking at video compression codecs.
The first is whether or not it is lossless.
When compressing information, especially pictures and videos, the compression codecs will often save space by removing data, often in the form of merging pixels, leading to a lower resolution, these are called lossy codecs.
While a lossless codec is obviously prefered, there are not many lossless video compression methods available and they often have limited compression.
Lossy codecs generally offer a greater reduction of file size, with the amount of data lost, depending on the codec.
This could be an acceptable tradeoff, depending on the size of the file and amount of quality lost.
Second is the amount of compression, often expressed as a ratio.
This is the ratio of the size of the original video file to the size of the compressed file.
This can be difficult to judge as some videos compress better than other depending on the what is being recorded.
Third, price is almost always a factor, as it is in this case.
If there is an open source alternative that is comparable to a paid version, then the open source would be more favorable.

Xvid is a an open source codec alternatice to a commercially sold codec, DivX \footnote{B. Clark, 'All You Need to Know about Video Codecs, Containers, and Compression', 2015. [Online]. Available: http://www.makeuseof.com/tag/all-you-need-to-know-about-video-codecs-containers-and-compression/ . [Accessed: 15-Nov-2016] }. %[2]
Xvid claims to be able to "compress video at a ratio of 200:1 or more" \footnote{xvid.com, 'Home', 2016. [Online]. Available: https://www.xvid.com/ . [Accessed: 15-Nov-2016] }. %[1].
While impressive, this is likely only under certain conditions.
Xvid is a "'lossy' compression but aims at removing just those picture details that are not important for human perception" \textsuperscript{2}. %[1].

FFV1 is a lossless video codec that is a part of FFmpeg a "leading multimedia framework, able to decode, encode, transcode, mux, demux, steam, filter and play pretty much anything that humans and machines have created"\footnote{ffmpeg.org, 'About FFmpeg'. [Online]. Available: http://ffmpeg.org/about.html . [Accessed: 15-Nov-2016] }. %[3].
Two sources have reported FFV1's compression ratio as roughly 100GB per hour to 45-50GB per hour \footnote{E. Lorrain, 'A Short Guide to Choosing a Digital Format for Video Archiving Masters', 2014. [Online]. Available: https://www.scart.be/?q=en/content/short-guide-choosing-digital-format-video-archiving-masters . [Accessed: 15-Nov-2016] }, approximately 2:1, to rougly 1.2:1 to 2.5:1\footnote{CS MSU Graphics \& Media Lab, \textit{Lossless Video Codecs Comparison}, Moscow: CS MSU Graphics \& Media Lab, 2004, p.14[Online]. Available: http://compression.ru/video/codec\_comparison/pdf/lossless\_codecs\_test\_en.pdf . [Accessed: 15-Nov-2016] }. % [4], [5]

H.264 is a video codec that was created by International Telecommunication Union\footnote{Vcodex, 'H.264 Advanced Video Coding'. [Online]. Available: https://www.vcodex.com/h264-resources/ . [Accessed: 15-Nov-2016] }, that has become "an industry standard for video compression"\textsuperscript{12}. % [6].
Cisco has recently decided to release an open source version under a BSD license and cover the royalties for anyone using their binary files\footnote{openh264.org, 'FAQ'. [Online]. Available: http://www.openh264.org/faq.html . [Accessed: 15-Nov-2016] }. % [7].
While this would allow the our product to use the H.264 codex, it would restrict us in the need to only use their binaries and always keep them up to date.
Should their be an issue, this could cause significant legal trouble.
H.264 has a lossless version that has a ratio of roughly 2:1\footnote{H. Lewetz, et al., 'Comparing Video Codecs and Containers for Archives', 2013. [Online]. Available: http://download.das-werkstatt.com/pb/mthk/info/video/comparison\_video\_codecs\_containers.html\#codec\_tests . [Accessed: 15-Nov-2016] }. %[8].

\begin{tabular}{|c|c|c|c|}
	\hline
	\textbf{Codec} & \textbf{Lossless} & \textbf{Compression Ratio} & \textbf{Open Source} \\
	\hline
	Xvid & No & 200:1(theoretical) & Yes \\
	\hline
	FFV1 & Yes & 2:1 (roughly) & Yes \\
	\hline
	OpenH264 & Yes & 2:1 (roughly) & Yes (with caveat) \\
	\hline
	
\end{tabular}


Selection

While Xvid has the best compression ratio, since it is not lossless, it is not the best choice.
OpenH264 has the roughly the same abilities as FFV1, but because of the potential legal problems and potential royalty payments this is also not the best choice.
This means that FFV1 is the best option for the long term compression codec.

\newpage
\subsection{Long-Term Storage} %Ben

The three option we have considered for video storage is .
The 
1 feed+data, 
2 feeds no data to be re-calculated, 
1 feed data baked into video

\begin{center}
	\begin{tabular}{|c|c|c|c|}
		
		\hline
		\textbf{} & \textbf{Languages available} & \textbf{Features available} & \textbf{Performance (rank)} \\
		\hline
		OpenCV & C, C++, Java, Python & Many & 1 \\
		\hline
		LTI-lib & C, C++ & Many & 2 \\
		\hline
		VXL & C, C++ & Numerics, Imaging, geometry, streaming I/O & 3 \\
		\hline
		
	\end{tabular}
\end{center}

\newpage
\subsection{Computer Vision Library} %Ben
The three options for Computer Vision (CV) libraries include OpenCV, LTI-Lib, and VXL.
Selecting a good CV library is essential for our project.
The goal of the CV library is to provide us with a large array of functions that we are able to utilize.
Every CV library we are looking at is open source and is free to use.
The library selected must be able to support our needs of being able to identify and track objects in real time through our live video feed.
It must have many available tools to simplify the identification and the tracking of objects.
The criteria that will be evaluated are languages available, features available, and performance.
The languages available is important because choosing a language we are already familiar with will give us an advantage.
We are hoping to use C/C++.
Feature available is also another very important criteria.
Specifically, we are looking for features that are able to simplify object tracking and detection.
Performance also plays a huge large factor in our choice.
We are looking for library that is as efficient as possible.
These libraries tend to be written in C/C++.

OpenCV is one of the most commonly used libraries for computer vision.
The OpenCV libraries are written in C/C++.
According to their website, they offer over 2500 algorithms [1].
The purpose of OpenCV is to offer a large number of function that the user is able to use to simplify difficult tasks.
This includes algorithms that are capable to identify and track objects, recognize faces, follow eye movements and many more [1].
OpenCV is used by many large companies like Google, Yahoo, Microsoft, Intel, IBM, Sony, Honda and Toyota [1]. 

LTI-Lib is also another Computer vision library that has many algorithms and features.
LTI-Lib's main goal is to provide an object oriented library in C++ [2].
It includes libraries for linear algebra, classification and clustering, image processing, as well as visualization and drawing tools [2].
There are a few research projects that utilize LTI-Lib including one at the University of Liege, Belgium where they do many things like machine learning, medical imaging, radar imaging, as well as sports video analysis.


VXL is another great computer vision library utilized by a lot of people.
Similar to OpenCV, the VXL libraries are written more in C++ [3].
The main libraries within VXL include numerics (VNL), imaging (VIL), geometry (VGL), and streaming I/O (VSL) [4].
They also have libraries for image processing, camera geometry, stereo, video manipulation, 3D imaging and many more [4].
VXL is written to be light, fast, and portable over many platforms [5].


\begin{center}
	\begin{tabular}{|c|c|c|c|}
		
		\hline
		\textbf{} & \textbf{Languages available} & \textbf{Features available} & \textbf{Performance (rank)} \\
		\hline
		OpenCV & C, C++, Java, Python & Many & 1 \\
		\hline
		LTI-lib & C, C++ & Many & 2 \\
		\hline
		VXL & C, C++ & Numerics, Imaging, geometry, streaming I/O & 3 \\
		\hline
		
	\end{tabular}
\end{center}

Based on the criteria needed for computer vision library, OpenCV has a large number of algorithms that we will be able to use as well as performs faster than the other libraries.
The speed performance test was done by Utkarsh Sinha.
The comparisons done were 2D DFT, resizing, optical flow, and neural net [6].
His findings show that OpenCV performs faster than both LTI-Lib and VXL with LTI-Lib coming in second [6].
Also, Based on reviews, OpenCV is just a lot more popular and widely used.
This is a huge positive because it means more references and documents will be available for use.
For our project I think OpenCV would be a lot more useful based on the criteria tested.

\newpage
\subsection{Computer Vision Underlying Algorithm} %Ben

Haar cascades
Background subraction

...
...

\newpage
\subsection{Live Compression} %Dylan

No compression
Camera live compresses
Computer live compresses

\newpage
\subsection{UI Overlay} %Dylan %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The UI overlay we select can be generated by one of the three following software packages:  OBS, Camtasia, or XSplit.  The goals for this software is to run with minimal overhead because it must perform its function while the backend is also doing the heavy lifting.  A major function we require from the selected software package is the ability to create an overlay on top of the incoming video feed.  In addition, depending on how the backend is set up, we will also need the overlay to place boxes around positions specified by the backend.  This is an effort to show the user where identified objects are in the image feed.

Open Broadcaster Software, frequently referred to as OBS, is an open source project designed for use in video editing and streaming.  OBS is also currently the most used software for live-streaming video feeds over the internet.  It is made to be as lightweight as possible while providing all required power to the user for the purposes of editing the video feed\footnote{obsproject.com. [Online]. Available: https://obsproject.com/ . [Accessed: 15-Nov-2016] }.

Camtasia is, at its core, a video editing software.  Since the rise in popularity of live streaming, Camtasia's creators (TechSmith) have added the capability to support live video streams.  They have an extensive toolset to allow you to manipulate what is shown on-screen due to their roots in video editing, but that also comes at the cost of marginally more overhead when running compared to other modern solutions\footnote{techsmith.com. [Online]. Available: https://www.techsmith.com/camtasia.html . [Accessed: 15-Nov-2016] }.

XSplit is a software designed primarially for use in web streaming a video.  As a result, it is designed to be run in the background while more strenuous tasks simultaneously run on the computer.  Popular addon packages allow it to generate pop-in elements on the overlay, primarially for Twitch donation notifications, but it can potentially be retooled for dynamic placement\footnote{xsplit.com. [Online]. Available: https://www.xsplit.com/ . [Accessed: 15-Nov-2016] }. \\

\begin{tabular}{|c|c|c|c|}
  \hline
  \textbf{Name} & \textbf{Overhead} & \textbf{Dynamic Overlay Placement} & \textbf{Open Source} \\
  \hline
  OBS Studio & Low & Yes & Yes \\ 
  \hline
  Camtasia & Moderate & Yes & No  \\ 
  \hline
  XSplit & Low & Yes & No \\ 
  \hline
\end{tabular} \\

Based on the capabilities of review technologies, OBS Studio is the selection for this project.  Camtasia has too much overhead due to its roots as a video editor.  XSplit is much more similar in performance reviews, but OBS has more power available to the user.  While XSplit can install packages to match this power, each package has an overhead cost, which places OBS on top.

\newpage
\subsection{Video to Velocity Formulas} %Dylan %Apparently a good term is Motion Estimation

In a sense video to velocity formulas already exist, however they exist to view their targets from a known, fixed distance and take advantage of hard-coded values.  In that way, we can certainly make use of what has been made, but we will have to heavily modify it for our purposes.  We can do so by using one variety of block-matching algorithm.  Our options include SDSP, Adaptive Rood, and Phase Correlation.  Because we are expecting to recieve many frames every second, the computer should be able to calculate the velocities of located objects with minimal overhead and maximum speed.

A Small Diamond Search Pattern (SDSP) is a heavily simplified version of what is referred to as an exhaustive search.  In a sense, an exhaustive search is a brute-force application to find the object's motion between frames, in any possible direction.  SDSP approximates the boundary conditions of an exhaustive search by searching in 8 directions around an object to where it may have traveled.  It repeats this any number of times until it believes the new location is approximately correct.  This method has very small variance from an exhaustive search while offering very reliable velocitied when set up correctly\footnote{ncbi.nlm.nih.gov. [Online]. Available: https://www.ncbi.nlm.nih.gov/labs/articles/18255398/ . [Accessed: 15-Nov-2016] }.

The Adaptive Rood Pattern Search is an algorithm that takes an object's previous motion and assumes it will approximately continue to use that motion between frames.  This allows it to potentially jump to the answer immediately, though in reality it will self-correct in a large number of cases.  This self-correction takes place through the use of a Diamond Search pattern, a variant of which was discussed above, after which it returns a velocity\footnote{semanticscholar.org. [Online]. Available: https://pdfs.semanticscholar.org/7f78/41b7b9c98b1e1f52282bdc3c2710cf83d3f0.pdf. [Accessed: 15-Nov-2016] }.

Phase Correlation is used to determine how far an object has moved on screen by comparing the two images and using the fourier shift transform to locate the change in x and y which the object traveled.  This gives highly accurate results when it works, but its reliability  comes at the cost of higher processing time required\footnote{semanticscholar.org. [Online]. Available: https://pdfs.semanticscholar.org/2c6c/6d3c94322e9ff75ff2143f7028bfab2b3c5f.pdf. [Accessed: 15-Nov-2016] }. \\

\begin{tabular}{|c|c|c|c|}
  \hline
  \textbf{Name} & \textbf{Overhead} & \textbf{Speed} & \textbf{Accuracy} \\
  \hline
  SDSP & Low & Fast & High \\ 
  \hline
  Adaptive Rood & Low & Fast & High  \\ 
  \hline
  Phase Correlation & Low & Slow & High \\ 
  \hline
\end{tabular} \\

Phase Correlation is clearly not an option we will wish to persue for this project, based on the conditions listed above.  The SDSP had the lowest overhead of any method available, however Adaptive Rood was notably faster in many scenarios.  It is worth noting Adaptive Rood has parts based around Diamond Search patterns which would make it more advanced than the pattern by itself, however it is questionable wether the objects in frame would move fast enough that we would need to predict their motion.  That said, I am selecting the Adaptive Rood method for this project.

\newpage
\section{Conclusion}

\section{References}

[1]"ABOUT | OpenCV", Opencv.org, 2016. [Online]. Available: http://opencv.org/about.html. [Accessed: 16- Nov- 2016].

[2]"LTI-Lib", Ltilib.sourceforge.net, 2016. [Online]. Available: http://ltilib.sourceforge.net/doc/homepage/index.shtml. [Accessed: 16- Nov- 2016].

[3]"VXL: 1. Introduction", Public.kitware.com, 2016. [Online]. Available: http://public.kitware.com/vxl/doc/release/books/core/book\_1.html. [Accessed: 16- Nov- 2016].

[4]"VXL - C++ Libraries for Computer Vision", Vxl.sourceforge.net, 2016. [Online]. Available: http://vxl.sourceforge.net/. [Accessed: 16- Nov- 2016].

[5]"Computer Recognition System For Detecting And Tracking Objects In 3D Environment", Csus-dspace.calstate.edu, 2016. [Online]. Available: http://csus-dspace.calstate.edu/bitstream/handle/10211.9/1249/Introduction%20to%20computer%20vision.pdf?sequence=2. [Accessed: 16- Nov- 2016].

[6]U. Sinha, "OpenCV vs VXL vs LTI: Performance Test - AI Shack - Tutorials for OpenCV, computer vision, deep learning, image processing, neural networks and artificial intelligence.", Aishack.in, 2016. [Online]. Available: http://aishack.in/tutorials/opencv-vs-vxl-vs-lti-performance-test/. [Accessed: 16- Nov- 2016].

%http://opencv.org/about.html [1]
%http://ltilib.sourceforge.net/doc/homepage/index.shtml [2]
%http://public.kitware.com/vxl/doc/release/books/core/book_1.html [3]
%http://vxl.sourceforge.net/ [4]
%http://csus-dspace.calstate.edu/bitstream/handle/10211.9/1249/Introduction%20to%20computer%20vision.pdf?sequence=2 [5]
%http://aishack.in/tutorials/opencv-vs-vxl-vs-lti-performance-test/[6]


%possible sections:  

%how the video feed is stored (1 feed+data, 2 feeds no data to be re-calculated, 1 feed data overlayed)
%connection speeds
%live compression
%long-term compression
%video to database storage
%mono- vs bi-focal
%computer vision
%speed formula
%legal accountability
%internal clocks/global shutters (syncronization)

\end{document}
